import gradio as gr
import numpy as np
from scipy.io import loadmat
import matplotlib.pyplot as plt

import torch
from transformers import AutoConfig

from sklearn.preprocessing import MinMaxScaler
from models.StuModels import TimeModule

from utils.preprocess_tools import calculate_csi_ratio, hampel_filter, phase_calibration, resample_csi_sequence, get_doppler_spectrum
from dataset.datasets import data_norm
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas


# --------------------------
# 1. æ¨¡å‹è®¾ç½®
# åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡
# --------------------------
llama_names = ['unsloth/Llama-3.2-1B', 'Qwen/Qwen2.5-1.5B']
gpt_names = ['openai-community/gpt2']

llm_name = 'openai-community/gpt2'
llm_config = AutoConfig.from_pretrained(llm_name)
d_llm = llm_config.hidden_size if llm_name in llama_names else llm_config.n_embd

csi_ratio_model = TimeModule(
    class_num=6,
    input_dim=30,
    token_kernels=[5, 11, 21],
    time_stride=4,
    llm_name='openai-community/gpt2',
    d_model=512,
    embed_size=d_llm,
    n_heads=8,
    num_encoder=6,
)

dfs_model = TimeModule(
    class_num=6,
    input_dim=121,
    token_kernels=[5, 11, 21],
    time_stride=10,
    llm_name='openai-community/gpt2',
    d_model=1024,
    embed_size=d_llm,
    n_heads=8,
    num_encoder=6,
)

csi_ratio_model.load_state_dict(torch.load("./param/csi_ratio_dis_stu_0.976.pth", map_location='cpu'))
dfs_model.load_state_dict(torch.load("./param/dfs_dis_stu_0.889.pth", map_location='cpu'))
csi_ratio_model.eval()
dfs_model.eval()
print("Model loaded successfully.")

# è®¾ç½®æ•°æ®å‚æ•°
csi_ratio_unified_len = 600
dfs_unified_len = 1800

# æ‰‹åŠ¿å›¾ç‰‡å¯¹åº”
gesture_names = {0: ['Push&Pull', './images/push.png'], 1: ['Sweep', './images/sweep.png'], 
                 2: ['Clap', './images/clap.png'], 3: ['Silde', './images/Side.png'], 
                 4: ['Draw-O', './images/draw-o.png'], 5: ['Draw-ZigZag', './images/draw-zigzag.png']}
print("Param Setting Successful.")

# --------------------------
# 2. æ•°æ®å¯¼å…¥å‡½æ•°
# --------------------------
def load_and_visualize(file):
    """åŠ è½½æ—¶é—´åºåˆ—æ–‡ä»¶å¹¶ç»˜åˆ¶åŸå§‹æ•°æ®"""
    mat = loadmat(file.name)
    csi_data = mat['csi_data']
    csi_data = csi_data.reshape(csi_data.shape[0], 3, -1)
    csi_data = csi_data.astype(np.complex128)
    abs_csi = np.abs(csi_data)

    plt.figure(figsize=(10, 4))
    for i in range(0,5):
        plt.plot(abs_csi[:,0,i])
    plt.title("Raw CSI Data")
    plt.xlabel("Time")
    plt.ylabel("CSI Amplitude")
    fig = plt.gcf()
    plt.close(fig)
    return csi_data, fig

# --------------------------
# 3. æ•°æ®é¢„å¤„ç†å‡½æ•°
# --------------------------
def preprocess_data(csi_data, method, progress=gr.Progress()):
    """é¢„å¤„ç†æ•°æ®"""
    progress(0, desc="ğŸ”„ æ­£åœ¨åˆå§‹åŒ–...")

    if method == "CSI-Ratio Phase(ä¿¡é“çŠ¶æ€ä¿¡æ¯æ¯”å€¼)":
        progress(0.2, desc="ğŸ“¡ è®¡ç®— CSI Ratio...")
        csi_ratio, antenna_index = calculate_csi_ratio(csi_data)
        csi_ratio = np.concatenate((csi_ratio[:, :antenna_index, :], csi_ratio[:, antenna_index+1:, :]), axis=1)
        
        progress(0.4, desc="ğŸ“ ç›¸ä½æ ¡å‡†ä¸­...")
        angle_csi_ratio = np.angle(csi_ratio)
        angle_csi_ratio = phase_calibration(hampel_filter(angle_csi_ratio))
        
        progress(0.6, desc="ğŸ” é‡é‡‡æ ·...")
        resample_csi_ratio = resample_csi_sequence(angle_csi_ratio, target_length=csi_ratio_unified_len)
    
        plt.figure(figsize=(10, 4))
        for i in range(0,30):
            plt.plot(resample_csi_ratio[:,0,i])
        plt.title("CSI-Ratio Phase")
        plt.xlabel("Time")
        plt.ylabel("Phase")
        fig = plt.gcf()
        plt.close(fig)

        tensor_csi_ratio = torch.tensor(resample_csi_ratio, dtype=torch.float32)
        tensor_csi_ratio = data_norm(tensor_csi_ratio, norm_type='mean_std')
        tensor_csi_ratio = tensor_csi_ratio.permute(1, 0, 2)

        progress(1.0, desc="âœ… å®Œæˆ CSI-Ratio å¤„ç†")
        return tensor_csi_ratio, fig
    elif method == "DFS(å¤šæ™®å‹’é¢‘ç§»)":
        progress(0.2, desc="ğŸ“¡ è®¡ç®—å¤šæ™®å‹’é¢‘è°±...")
        dfs, t, f = get_doppler_spectrum(csi_data)

        plt.figure(figsize=(10, 6))
        plt.pcolormesh(t, np.fft.fftshift(f), np.fft.fftshift(dfs), shading='gouraud', cmap='jet')
        plt.title('Doppler Frequency Shift', fontsize=14)
        plt.ylabel('Frequency', fontsize=12)
        plt.xlabel('Time', fontsize=12)
        plt.colorbar(label='Magnitude')
        fig = plt.gcf()
        plt.close(fig)

        progress(0.6, desc="ğŸ” è¡¥é›¶/æˆªæ–­...")
        _, sample_index = dfs.shape
        if sample_index >= dfs_unified_len:
            doppler_spectrum = dfs[:, :dfs_unified_len]
        else:
            doppler_spectrum = np.concatenate([dfs, np.zeros((dfs.shape[0], dfs_unified_len-sample_index))], axis=1)
        tensor_dfs = torch.tensor(doppler_spectrum, dtype=torch.float32)
        tensor_dfs = tensor_dfs.permute(1, 0)
        tensor_dfs = tensor_dfs.unsqueeze(0)

        progress(1.0, desc="âœ… å®Œæˆ DFS å¤„ç†")
        return tensor_dfs, fig
    else:
        raise ValueError("Invalid method selected.")

# --------------------------
# 4. æ¨¡å‹é¢„æµ‹åˆ†ç±»
# --------------------------
def fig_to_numpy(fig):
    canvas = FigureCanvas(fig)
    canvas.draw()
    img = np.array(canvas.renderer.buffer_rgba())
    return img
def predict(data, method, progress=gr.Progress()):
    """ä½¿ç”¨æ¨¡å‹é¢„æµ‹/åˆ†ç±»"""
    progress(0, desc="ğŸ” æ­£åœ¨è¿›è¡Œæ‰‹åŠ¿è¯†åˆ«...")

    input_tensor = data
    with torch.no_grad():
        if method == "CSI-Ratio Phase(ä¿¡é“çŠ¶æ€ä¿¡æ¯æ¯”å€¼)":
            action_logits, _= csi_ratio_model.predict(input_tensor, decoder_mask=True)
            action_probs = torch.mean(torch.softmax(action_logits, dim=-1), dim=0)
            action_index = torch.argmax(action_probs, dim=-1)
            action_probs = action_probs.numpy()
            progress(0.5, desc="ğŸ§  åˆ†æä¸­...")
        else:
            action_logits, action_index = dfs_model.predict(input_tensor, decoder_mask=True)
            action_probs = torch.softmax(action_logits, dim=-1).numpy()[0]
            progress(0.5, desc="ğŸ§  åˆ†æä¸­...")

    action_prob = action_probs[action_index]
    action_label = gesture_names[action_index.item()][0]
    action_fig_path = gesture_names[action_index.item()][1]
    
    # åŠ è½½å›¾åƒå¹¶ç»˜åˆ¶
    img = plt.imread(action_fig_path)
    plt.figure(figsize=(4, 4))
    plt.imshow(img)
    plt.axis("off")
    fig = plt.gcf()
    plt.close(fig)
    img_np = fig_to_numpy(fig)

    result_text = f"ğŸ¯ è¯†åˆ«ç»“æœï¼š{action_label}\nğŸ“ˆ ç½®ä¿¡åº¦ï¼š{action_prob:.2%}"
    progress(1.0, desc="âœ… å®Œæˆ")
    return result_text, img_np

# --------------------------
# 5. Gradioç•Œé¢æ„å»º
# --------------------------
with gr.Blocks(title="åŸºäºé¢„è®­ç»ƒå¤§æ¨¡å‹çš„æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ", css=".gradio-container { background-color: #f5f7fa; }") as app:
    gr.Markdown("## ğŸ™‹â€â™‚ï¸æ‰‹åŠ¿è¯†åˆ«å·¥å…·")
    
    with gr.Tab("1. æ•°æ®åŠ è½½"):
        with gr.Row():
            file_input = gr.File(label="ä¸Šä¼ CSIæ–‡ä»¶(matæ–‡ä»¶)")
            load_btn = gr.Button("åŠ è½½æ•°æ®")
        raw_plot = gr.Plot(label="åŸå§‹æ•°æ®å¯è§†åŒ–")
        raw_data = gr.State() # éšè—ä¼ é€’æ•°æ®
    
    with gr.Tab("2. æ•°æ®å¤„ç†"):
        with gr.Row():
            method_select = gr.Radio(
                choices=["CSI-Ratio Phase(ä¿¡é“çŠ¶æ€ä¿¡æ¯æ¯”å€¼)", "DFS(å¤šæ™®å‹’é¢‘ç§»)"],
                label="é€‰æ‹©å¤„ç†æ–¹å¼",
                value="CSI-Ratio Phase",
                elem_classes=["method-radio"]
            )

        process_btn = gr.Button("âš™ï¸ å¼€å§‹å¤„ç†æ•°æ®", variant="primary")

        with gr.Column(scale=1):
            gr.Markdown("**âŒ› å¤„ç†è¿›åº¦**")
            progress_bar = gr.Progress()
        with gr.Column(scale=1):
            processed_plot = gr.Plot(label="ğŸ“Š å¤„ç†åçš„æ•°æ®å¯è§†åŒ–", elem_id="plot-area")

        processed_data = gr.State()

        # è‡ªå®šä¹‰CSSæ ·å¼
        app.css += """
            .method-radio {
                font-weight: bold;
            }

            .status-box {
                background-color: #f8f9fa;
                border-left: 4px solid #007bff;
                padding: 10px;
                font-size: 15px;
                animation: fadeIn 0.6s ease-in-out;
            }

            .gr-button {
                border-radius: 8px;
                background-color: #4a90e2;
                color: white;
                box-shadow: 0 3px 6px rgba(0,0,0,0.1);
                transition: all 0.3s ease;
            }

            .gr-button:hover {
                transform: scale(1.03);
                box-shadow: 0 6px 12px rgba(0,0,0,0.15);
            }

            @keyframes fadeIn {
                from { opacity: 0; }
                to { opacity: 1; }
            }
        """
    
    with gr.Tab("3. æ¨¡å‹é¢„æµ‹"):
        predict_btn = gr.Button("ğŸ§  è¿è¡Œé¢„æµ‹", variant="primary")

        with gr.Column(scale=1):
            gr.Markdown("**âŒ› é¢„æµ‹ç»“æœ**")
            progress_bar = gr.Progress()
            result_text = gr.Textbox(
                label="é¢„æµ‹ç»“æœ",
                value="ç­‰å¾…é¢„æµ‹...",
                lines=2,
                interactive=False,
                elem_classes=["result-box"]
            )
        with gr.Column(scale=1):
            gr.Markdown("**ğŸ¤ æ‰‹åŠ¿åŠ¨ä½œç¤ºæ„å›¾**")
            image_output = gr.Image(label="æ‰‹åŠ¿åŠ¨ä½œå›¾åƒ", interactive=False)

        # è‡ªå®šä¹‰CSSæ ·å¼
        app.css += """
            .result-box {
                font-size: 16px;
                font-weight: bold;
                background-color: #f0f8ff;
                border: 2px solid #87ceeb;
                padding: 10px;
                color: #333;
                animation: fadeIn 1s ease-in-out;
            }
            
            @keyframes fadeIn {
                from { opacity: 0; transform: translateY(10px); }
                to { opacity: 1; transform: translateY(0); }
            }
        """
    
    # --------------------------
    # 4. äº‹ä»¶ç»‘å®š
    # --------------------------
    load_btn.click(
        fn=load_and_visualize,
        inputs=file_input,
        outputs=[raw_data, raw_plot]
    )
    
    process_btn.click(
        fn=preprocess_data,
        inputs=[raw_data, method_select],
        outputs=[processed_data, processed_plot]
    )
    
    predict_btn.click(
        fn=predict,
        inputs=[processed_data, method_select],
        outputs=[result_text, image_output]
    )

# --------------------------
# 5. å¯åŠ¨åº”ç”¨
# --------------------------
if __name__ == "__main__":
    app.launch(share=False)  # è®¾ç½® share=True ç”Ÿæˆä¸´æ—¶å…¬å…±é“¾æ¥
